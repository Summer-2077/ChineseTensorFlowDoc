{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60RdWsg1tETW"
   },
   "source": [
    "# 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEu3q4jmpKVT"
   },
   "source": [
    "我们推荐使用`tf.keras`作为一个高层API来构建神经网络。大多数TensorFlow API可以基于即刻执行使用。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Py0m-N6VgQFJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TluWFcB_2nP5"
   },
   "outputs": [],
   "source": [
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSFfVVjkrrsI"
   },
   "source": [
    "## 层：有用操作的一般集合\n",
    "\n",
    "多数时候，你写机器学习模型代码时，你希望使用高层抽象，而不是单个操作和单个变量的操作。\n",
    "\n",
    "很多机器学习模型通过组合和堆砌相对简单的层来表达，TensorFlow提供了很多通用层和简单方法让你编写具体应用层，可以从头编写，也可以组合现有层。\n",
    "\n",
    "在tf.keras包中TensorFlow包括完整的[Keras](https://keras.io) API，在构建自己模型时，Keras 层非常有用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PyXlPl-4TzQ"
   },
   "outputs": [],
   "source": [
    "# 在tf.keras.layers包中，层是对象。通过构建对象创建层。 \n",
    "# 多数层的第一个参数是输出维或信道的大小\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "\n",
    "# 输入维的大小通常是不需要的，因为它可以在层第一次使用时推导出来。\n",
    "# 但是，如果你想指定，可以给出，这在某些复杂模型中有用。\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fn69xxPO5Psr"
   },
   "source": [
    "可以在文档中找到预先定义的层的完整列表。它包括Dense（完全连接的层），Conv2D，LSTM，BatchNormalization，Dropout等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3XKNknP5Mhb"
   },
   "outputs": [],
   "source": [
    "# 通过调用使用层.\n",
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wt_Nsv-L5t2s"
   },
   "outputs": [],
   "source": [
    "# 层有很多有用的属性和方法。例如，你可以使用`layer.variables` 和\n",
    "# `layer.trainable_variables`查看层的变量.\n",
    "# 在这种情况下，全连接层有权值和偏移变量.\n",
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ilvKjz8_4MQ"
   },
   "outputs": [],
   "source": [
    "# 变量也可以通过访问器来访问T\n",
    "layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0kDbE54-5VS"
   },
   "source": [
    "## 实现定制层\n",
    "\n",
    "实现自己的层的最佳方法是扩展tf.keras.Layer类并实现：\n",
    "\n",
    "1. `__init__ `，您可以在其中进行所有与输入无关的初始化\n",
    "2. `build` ，您知道输入张量的形状，并可以进行其余的初始化\n",
    "3. `call` ，在其中进行前向计算\n",
    "\n",
    "请注意，您不必等到调用build来创建变量时，也可以在__init__创建它们。但是，在build中创建它们的优点是，它可以根据将在其上进行操作的输入的形状来进行后面变量创建。另一方面，在__init__创建变量将意味着需要明确指定创建变量所需的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Byl3n1k5kIy"
   },
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_outputs):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    self.num_outputs = num_outputs\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.kernel = self.add_weight(\"kernel\",\n",
    "                                  shape=[int(input_shape[-1]),\n",
    "                                         self.num_outputs])\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.matmul(input, self.kernel)\n",
    "\n",
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrmBsYGOnuGO"
   },
   "outputs": [],
   "source": [
    "_ = layer(tf.zeros([10, 5])) # 调用层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bsLjiPfnvat"
   },
   "outputs": [],
   "source": [
    "print([var.name for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk8E2vY0-z4Z"
   },
   "source": [
    "如果代码尽可能使用标准层，则更易于阅读和维护，因为其他读者会熟悉标准层的行为。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qhg4KlbKrs3G"
   },
   "source": [
    "## 模型: 组合层\n",
    "\n",
    "\n",
    "机器学习模型中许多有趣的类似于层的对象(模型)都是通过组合现有层来实现的。例如，resnet中的每个残差块都是卷积、批处理规范化和跳转连接的组合。层可以嵌套在其他层中。\n",
    "\n",
    "通常，当您需要使用诸如`Model.fit` ， `Model.evaluate`和`Model.save`等模型方法时，您需要从`keras.Model`继承。\n",
    "\n",
    "`keras.Model` （而不是keras.layers.Layer ）提供的另一个功能是，除了跟踪变量之外， `keras.Model`还跟踪其内部层，使它们更易于检查。\n",
    "\n",
    "例如，这是一个ResNet块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N30DTXiRASlb"
   },
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7D8ZR5mqtokj"
   },
   "outputs": [],
   "source": [
    "_ = block(tf.zeros([1, 2, 3, 3])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJ8rzFpdoE_m"
   },
   "outputs": [],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dewldLuDvQRM"
   },
   "outputs": [],
   "source": [
    "len(block.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrqIXeSetaYi"
   },
   "outputs": [],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wYfucVw65PMj"
   },
   "source": [
    "但是，在很多时候，组成多层的模型只是简单地逐层调用。使用`tf.keras.Sequential`只需很少的代码即可完成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9frk7Ur4uvJ"
   },
   "outputs": [],
   "source": [
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVAsbFITuScB"
   },
   "outputs": [],
   "source": [
    "my_seq.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "custom_layers.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
